import{_ as s}from"./_plugin-vue_export-helper.cdc0426e.js";import{o as r,c as n,a as e,b as i,d as l,e as o,r as t}from"./app.59944050.js";const d="/assets/msg-model1.10e9f516.png",c="/assets/msg-model2.4206afd0.png",p="/assets/kafka-architecture.3a6af2da.png",h="/assets/sendMsg.fc918e65.png",m="/assets/writeMsg.dbcc90b4.png",u="/assets/producer.a2320e72.png",g="/assets/partition.e434178f.png",b="/assets/producer2.27d92749.png",k="/assets/producer3.251d5b11.png",f="/assets/consumer-msg.da6e32de.png",v={},_=o('<h2 id="消息中间件好处" tabindex="-1"><a class="header-anchor" href="#消息中间件好处" aria-hidden="true">#</a> 消息中间件好处</h2><ol><li>解耦</li><li>异步</li><li>削峰</li></ol><h2 id="消息队列的通信模式" tabindex="-1"><a class="header-anchor" href="#消息队列的通信模式" aria-hidden="true">#</a> 消息队列的通信模式</h2><ol><li>点对点。基于<strong>拉取</strong>或者<strong>轮询</strong>的消息传送模型，发送到队列的消息被一个且只有一个消费者进行处理 <img src="'+d+'" alt="image"></li><li>发布订阅 <img src="'+c+'" alt="image"></li></ol><h2 id="kafka-架构" tabindex="-1"><a class="header-anchor" href="#kafka-架构" aria-hidden="true">#</a> kafka 架构</h2><p><img src="'+p+'" alt="image"></p><ol><li>消费者组。同一个分区的数据只能被消费者组中的一个消费者消费；同一个消费者组的消费者可以消费同一个 topic 的不同分区的数据</li><li>producer 采用发送 push 的方式将消息发到 broker 上，broker 存储后。由 consumer 采用 pull 模式订阅并消费信息</li><li>partition 是文件，支持多个副本</li></ol><h2 id="优点" tabindex="-1"><a class="header-anchor" href="#优点" aria-hidden="true">#</a> 优点</h2><ol><li>顺序读写磁盘。 <ol><li>顺序读写。按记录的逻辑顺序进行读、写操作的存取方法，即按照信息在存储器中的实际位置所决定的顺序使用信息，不容易删除数据。 2.在 Partition 末尾追加</li></ol></li><li>MMAP 内存映射文件。直接利用操作系统的 Page 来实现文件到物理内存的直接映射，完成映射后对物理内存的操作会被同步到硬盘上。 <ol><li>原理。可以像读写硬盘一样读写内存（逻辑内存），不必关心内存的大小</li></ol></li><li>零拷贝。所有数据通过 DMA（直接内存访问）来进行传输，没有在内存层面去复制数据</li><li>数据批量处理</li><li>kafka引擎读写行为特点 <ul><li>数据的消费频率随时间变化，越久远的数据消费频率越低</li><li>每个分区只有Leader提供读写服务</li><li>对于一个客户端而言，消费行为是线性的，数据并不会重复消费</li></ul></li></ol><h2 id="工作流程分析" tabindex="-1"><a class="header-anchor" href="#工作流程分析" aria-hidden="true">#</a> 工作流程分析</h2><h3 id="发送数据" tabindex="-1"><a class="header-anchor" href="#发送数据" aria-hidden="true">#</a> 发送数据</h3><p><img src="'+h+'" alt="image"></p><ul><li>消息写入 leader 后，follower 是主动的去 leader 进行同步。</li><li>producer 采用<strong>push 模式</strong>将数据发布到 broker，每条消息追加到分区中，顺序写入磁盘，保证同一分区内的数据是<strong>有序</strong>的。 <img src="'+m+`" alt="image"></li></ul><ol><li><p>写入原则</p><ul><li>按指定 partition 写入</li><li>按 key 的 hash 值算出 partition 写入【消息被均匀的分布到不同的 partition 中，才能实现了水平扩展】</li><li>没有设置 key，轮询选出一个 partition</li></ul></li><li><p>消息可靠性保证</p><ul><li>0。不需要等到集群返回，不能保证消息发送成功。</li><li>1。只要 leader 应答就可以发送下一条，只确保 leader 发送成功</li><li>all[-1]。需要所有 follower 都完成 leader 的同步才会发送下一条，确保 leader 发送成功和所有的副本完成备份</li></ul></li><li><p>CP【一致性和分区容错性】配置</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token assign-left variable">request.required.acks</span><span class="token operator">=</span>-1
min.insync.replicas <span class="token operator">=</span> <span class="token variable">\${N<span class="token operator">/</span>2 + 1}</span>
unclean.leader.election.enable <span class="token operator">=</span> <span class="token boolean">false</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>AP【可用性和分区容错性】配置</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token assign-left variable">request.required.acks</span><span class="token operator">=</span><span class="token number">1</span>
min.insync.replicas <span class="token operator">=</span> <span class="token number">1</span>
unclean.leader.election.enable <span class="token operator">=</span> <span class="token boolean">false</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>Producer写入 Server端的I/O线程统一将请求中的数据写入到操作系统的PageCache后立即返回，当消息条数到达一定阈值后，Kafka应用本身或操作系统内核会触发强制刷盘操作 <img src="`+u+'" alt="image"></p></li></ol><h3 id="kafka-消息备份和同步" tabindex="-1"><a class="header-anchor" href="#kafka-消息备份和同步" aria-hidden="true">#</a> kafka 消息备份和同步</h3><ol><li>根据分区的多副本策略来解决消息的备份问题</li><li>名词解释 <ol><li>ISR : leader 副本保持一定同步的 follower 副本, 包括 leader 副本自己，叫 In Sync Replica，最终会反馈到 zookeeper 上。</li><li>AR: 所有副本 (replicas) 统称为 assigned replicas, 即 AR</li><li>OSR: follower 同 leader 同步数据有一些延迟的节点</li><li>HW: Highwater, 俗称高水位，它表示了一个特定的消息偏移量(offset), 在一个 parttion 中 consumer 只能拉取这个 offset 之前的消息(此 offset 跟 consumer offset 不是一个概念) ；</li><li>LEO: LogEndOffset, 日志末端偏移量, 用来表示当前日志文件中下一条写入消息的 offset；</li><li>leader HW: 该 Partititon 所有副本的 LEO 最小值；</li><li>follower HW: min(follower 自身 LEO 和 leader HW)；</li><li>Leader HW = 所有副本 LEO 最小值；</li><li>Follower HW = min(follower 自身 LEO 和 leader HW)。</li></ol></li><li>副本 <ol><li>定义。在不同节点上持久化同一份数据，当某一个节点上存储的数据丢失时，可以从副本上读取该数据</li><li>分配规则。每个Broker都有均等分配Partition的Leader机会 <img src="'+g+'" alt="image"></li><li>分配算法。 <ul><li>将所有N Broker和待分配的i个Partition排序</li><li>将第i个Partition分配到第(i mod n)个Broker上</li><li>将第i个Partition的第j个副本分配到第((i + j) mod n)个Broker上</li></ul></li></ol></li><li>消息接收 <ol><li>主要利用了操作系统的<strong>ZeroCopy</strong>机制，当Kafka Broker接收到读数据请求时，会向操作系统发送sendfile系统调用，操作系统接收后，首先试图从PageCache中获取数据 <img src="'+b+'" alt="image"></li><li>如果数据不存在，会触发缺页异常中断将数据从磁盘读入到临时缓冲区中，随后通过DMA操作直接将数据拷贝到网卡缓冲区中等待后续的TCP传输。 <img src="'+k+'" alt="image"></li></ol></li></ol><h3 id="保存数据" tabindex="-1"><a class="header-anchor" href="#保存数据" aria-hidden="true">#</a> 保存数据</h3><blockquote><p>顺序写入的方式将数据保存到磁盘</p></blockquote><h4 id="partition-结构" tabindex="-1"><a class="header-anchor" href="#partition-结构" aria-hidden="true">#</a> partition 结构</h4><blockquote><p>以文件夹的方式在服务器中存储</p></blockquote><ol><li>影响分区数量的因素</li></ol><ul><li>生产者的峰值带宽</li><li>消费者的峰值带宽</li><li>消费者的消费能力。同一个消费组里同一个分区只能被一个消费者消费</li></ul><ol start="2"><li>选取合适的分区数量 <blockquote><p>建议分区的数量一定要大于等于消费者的数量来实现最大并发</p></blockquote></li></ol><ul><li>Num=max(T/PT,T/CT)=T/min(PT,CT) <ol><li>Num：分区数</li><li>T：目标吞吐量</li><li>PT：生产者写入单个分区的最大吞吐量</li><li>CT：消费者从单个分区消费的最大吞吐</li><li>分区数量=T/PT 和 T/CT 中的</li></ol></li><li>PT 影响的因素：批处理的规模、压缩算法、确认机制、副本数等有关</li></ul><ol start="3"><li>信息参考</li></ol><ul><li>单个分区可以实现消息的顺序写入</li><li>单个分区只能被同消费组的单个消费者进程消费</li><li>单个消费者进程可同时消费多个分区</li><li>分区越多，当 Leader 节点失效后，其他分区重新进行 Leader 选举的耗时会越长</li><li>分区的数量是可以动态增加的，只增不减，但增加会出现 rebalance 的情况</li></ul><h4 id="message-结构" tabindex="-1"><a class="header-anchor" href="#message-结构" aria-hidden="true">#</a> message 结构</h4><ol><li>offset。占 8byte 的有序 id 号，唯一确定每条消息在 partition 内的位置</li><li>消息大小</li><li>消息体。</li></ol><h4 id="文件存储设计特点" tabindex="-1"><a class="header-anchor" href="#文件存储设计特点" aria-hidden="true">#</a> 文件存储设计特点</h4><ol><li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li><li>通过<strong>索引</strong>信息可以快速定位message和确定response的最大大小。</li><li>通过<strong>index元数据</strong>全部映射到memory，可以避免segment file的IO磁盘操作。</li><li>通过<strong>索引文件</strong>稀疏存储，可以大幅降低index文件元数据占用空间大小。</li></ol><h4 id="存储策略" tabindex="-1"><a class="header-anchor" href="#存储策略" aria-hidden="true">#</a> 存储策略</h4><ol><li>基于时间，默认 7 天；</li><li>基于大小，默认 128MB;</li></ol><h3 id="消费数据" tabindex="-1"><a class="header-anchor" href="#消费数据" aria-hidden="true">#</a> 消费数据</h3><p><img src="'+f+`" alt="image"></p><ol><li>点对点模式。由消费者主动去 kafka 集群拉取消息</li><li>消费者组 consumer 的数量与 partition 的数量一致</li></ol><h4 id="消费场景" tabindex="-1"><a class="header-anchor" href="#消费场景" aria-hidden="true">#</a> 消费场景</h4><ol><li>AutoCommit（实际消息会丢）</li></ol><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>    enable.auto.commit <span class="token operator">=</span> <span class="token boolean">true</span>
    // 自动提交的时间间隔
    auto.commit.interval.ms
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>手动 commit（at least once，消息重复，重启会丢）</li></ol><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>    // oldest:topic里最早的消息，大于commit的位置，小于HW，也受到broker上消息保留时间和位移影响，不保证一定能消费到topic起始位置的消息
    sarama.offset.initial （oldest, newest）
    // 主题偏移量日志文的保留时长，默认设为1440s
    offsets.retention.minutes
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="消费原理" tabindex="-1"><a class="header-anchor" href="#消费原理" aria-hidden="true">#</a> 消费原理</h4><ol><li>数据异步批量的存储在磁盘中，采用批量刷盘的做法进行，即按照一定的消息量和时间间隔进行刷盘。先存储到页缓存（Page cache）中，按照时间或者其他条件进行刷盘，或通过 fsync 命令强制刷盘。做不到不丢失消息，只能通过调整刷盘机制的参数缓解该情况</li><li>通过 ack 的方式来处理消息丢失的情况</li></ol><h2 id="指令" tabindex="-1"><a class="header-anchor" href="#指令" aria-hidden="true">#</a> 指令</h2><ol><li>创建 topic</li></ol><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>./kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--topic</span> dev2wx --replication-factor <span class="token number">1</span> <span class="token parameter variable">--partitions</span> <span class="token number">2</span> <span class="token parameter variable">--zookeeper</span> master:2181
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ol start="2"><li>查看 topic</li></ol><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>./kafka-topics.sh <span class="token parameter variable">--list</span> <span class="token parameter variable">--zookeeper</span> master:2181
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ol start="3"><li>查看 consumer list</li></ol><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>./kafka-consumer-groups.sh --bootstrap-server master:9092 --list
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>./kafka-topics.sh --list --zookeeper master:2181 4. 消费积压情况</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>./kafka-consumer-groups.sh --bootstrap-server master:9092 <span class="token parameter variable">--describe</span> <span class="token parameter variable">--group</span> logstash
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="资料" tabindex="-1"><a class="header-anchor" href="#资料" aria-hidden="true">#</a> 资料</h2>`,52),x={href:"https://mp.weixin.qq.com/s/T6gCc8OBgyV-yeAg_MUzPQ",target:"_blank",rel:"noopener noreferrer"},P={href:"https://blog.csdn.net/MeituanTech/article/details/112645937",target:"_blank",rel:"noopener noreferrer"},T={href:"https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html",target:"_blank",rel:"noopener noreferrer"},w={href:"https://blog.csdn.net/lizhitao/article/details/25667831",target:"_blank",rel:"noopener noreferrer"};function L(q,y){const a=t("ExternalLinkIcon");return r(),n("div",null,[_,e("ol",null,[e("li",null,[e("a",x,[i("简单理解 kafka 的消息可靠性"),l(a)])]),e("li",null,[e("a",P,[i("基于SSD的Kafka应用层缓存架构设计与实现"),l(a)])]),e("li",null,[e("a",T,[i("Kafka文件存储机制那些事"),l(a)])]),e("li",null,[e("a",w,[i("kafka服务器配置"),l(a)])])])])}const O=s(v,[["render",L],["__file","index.html.vue"]]);export{O as default};
